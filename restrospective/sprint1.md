## 1st Sprint SPG Project RETROSPECTIVE (Team R1)

### PROCESS MEASURES

#### Macro statistics

- Number of stories committed vs done

  We submitted 4 stories including the registration and login system with design and code but without testing. (Whenever we complete the tests for the submitted stories they will be done) .

- Total points committed vs done

  Considering the lack of tests we cannot consider as fully finished any of the stories. We can say that we committed 47 points and we submitted them all (just waiting for the testing).

- Nr of hours planned vs spent (as a team)

  According to the data recorded in the YouTrack, hours spent Information is following: 

  In progress: 23.5h, Submitted:8h and Verified:6.5h, 

  Total time spent:38h(4d and 6h).

  

#### Detailed statistics

| Stroy                                     | #Tasks | Points | Hours est. | Hour Actual |
| ----------------------------------------- | ------ | ------ | ---------- | ----------- |
| Learn Flask + Setup DB + Porject Template | 4      |        | 16         | 19          |
| Enter Client Order                        | 2      | 8      | 6          | 5           |
| Enter New Client                          | 2      | 10     | 8          | 6           |
| Browse Products                           | 2      | 21     | 8          | 6           |
| Registration                              | 3      | 8      | 2          | 2           |

- Hours per task

  average: 5.8h,  standard deviation: 4.711

  Total task estimation error ratio:  1.379

------



### QUALITY MEASURES

#### Unit Testing:

Estimated 3h, almost 4hrs spent and not fully finished due to some technical complications that blocked testing from working fine. The problem and the testing now got carried as a technical debt card that needs to be addressed.

#### E2E testing:

Not planned or estimated for this sprint.

#### Code review:

Not specifically estimated, more included in the other tasks, a good estimate would be around half an hour per person, so 2.5 hrs in total.

#### Technical Debt management:

Not planned for this second sprint other than reviewing SonarQube and taking that into the next sprint.

​	Ratings: No data

​	Reliability: C -- 43 bugs

​	Security: A - 0 vulnerabilities

​	Coverage: 0% (not yet included in the branch analysed)

​	Security Review: E - 9 security hotspots

------



### ASSESSMENT

- What caused your errors in estimation (if any)?

The wrong assessments for some tasks, it causes us to spend more time on it directly.

- What lessons did you learn (both positive and negative) in this sprint?

P1: I learned how to audit python code and try to fix them, it improves my ability in security. And this sprint also told me I should talk with our team more frequently.

P2: We have learnt that we need to be more collaborative if we want to achieve great results. Poor collaboration leads to discrete results and that is not what we want.

- Which improvement goals set in the previous retrospective were you able to achieve?

This sprint, we have to be more efficient trying to complete more stories and we have to manage to set up the tests  and try to fix some bugs for the whole project.

- Which ones were you not able to achieve? Why?

We were not able to properly divide the tasks due to the lack of communication and due to the lack of a person in charge of managing the project. For the second sprint we will organise everything better and meet more often in order to have continuous feedback on the status of the different tasks.

- Improvement goals for the next sprint and how to achieve them (technical tasks, team coordination, etc.)

We should try to get in touch with the other members more often, checking more than once a day all the different communication canals we use to stay updated on the state of the project.

- One thing you are proud of as a Team!!

Even though there have been problems at the start of the sprint we still managed to carry out a valuable product which is very user friendly.

------

